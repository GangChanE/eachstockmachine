import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from scipy.stats import linregress, skew
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
from pandas.tseries.offsets import BDay
import warnings

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# âš™ï¸ 0. ê³ ì† ì—°ì‚° í•¨ìˆ˜
# ---------------------------------------------------------
X_ARR_20 = np.arange(20)
X_MEAN_20 = 9.5
X_VAR_SUM_20 = 665.0 

X_ARR_60 = np.arange(60)
X_MEAN_60 = 29.5
X_VAR_SUM_60 = 17990.0

def calc_fast_slope(prices, X_ARR, X_MEAN, X_VAR_SUM):
    y_mean = np.mean(prices)
    slope = np.sum((X_ARR - X_MEAN) * (prices - y_mean)) / X_VAR_SUM
    current_price = prices[-1]
    return (slope / current_price) * 100 if current_price > 0 else 0.0

def calc_sigma(prices, X_ARR, X_MEAN, X_VAR_SUM):
    y_mean = np.mean(prices)
    slope = np.sum((X_ARR - X_MEAN) * (prices - y_mean)) / X_VAR_SUM
    intercept = y_mean - slope * X_MEAN
    trend_line = slope * X_ARR + intercept
    std = np.std(prices - trend_line)
    return (prices[-1] - trend_line[-1]) / std if std > 0 else 0.0

# ---------------------------------------------------------
# âš™ï¸ 1. UI ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(page_title="Quantum Oracle V22", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® The Quantum Oracle V22: AI ì˜ˆì¸¡ vs í˜„ì‹¤ ê²€ì¦ê¸°")
st.markdown("""
ê³¼ê±°ì˜ íŠ¹ì • ë‚ ì§œë¡œ íƒ€ì„ë¨¸ì‹ ì„ íƒ€ê³  ëŒì•„ê°€, **ê·¸ë‚ ê¹Œì§€ì˜ ë°ì´í„°ë§Œìœ¼ë¡œ AIë¥¼ í•™ìŠµ**ì‹œí‚µë‹ˆë‹¤.  
ì´í›„ Tì¼ ë™ì•ˆ AIê°€ ì˜ˆì¸¡í•œ ìŠ¬ë¡œí”„/ì‹œê·¸ë§ˆ ê¶¤ì (ì ì„ )ê³¼ **ì‹¤ì œ ì‹œì¥ì—ì„œ ì¼ì–´ë‚œ í˜„ì‹¤ ê¶¤ì (ì‹¤ì„ )**ì„ ê²¹ì³ ê·¸ë ¤ì„œ AIì˜ ì ì¤‘ë¥ ì„ ëˆˆìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
""")

with st.sidebar:
    st.header("âš™ï¸ íƒ€ì„ë¨¸ì‹  ê²€ì¦ ì„¤ì •")
    target_ticker = st.text_input("ì¢…ëª© ì½”ë“œ (í‹°ì»¤)", value="069500.KS")
    target_date = st.date_input("í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (íƒ€ì„ë¨¸ì‹  íƒ‘ìŠ¹ì¼)")
    target_t = st.number_input("ë‹¨ê¸° ì˜ˆì¸¡ ê¸°ê°„ (Tì¼)", min_value=1, max_value=60, value=10, step=1, help="ë‹¨ê¸° ìŠ¤ìœ™ì„ ìœ„í•´ ë³´í†µ 5~20ì¼ ì‚¬ì´ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
    run_btn = st.button("ğŸš€ ì˜ˆì¸¡ vs í˜„ì‹¤ ë¹„êµ ê°€ë™", type="primary")

# ---------------------------------------------------------
# âš™ï¸ 2. AI í•™ìŠµ ë° ê²€ì¦ ì—”ì§„
# ---------------------------------------------------------
@st.cache_data(show_spinner=False, ttl=3600)
def backtest_ai_prediction(ticker, target_date, T):
    try:
        raw = yf.download(ticker, start="2012-01-01", progress=False)
        if raw.empty: return None, "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨."
            
        df_all = raw.copy()
        if isinstance(df_all.columns, pd.MultiIndex):
            df_all.columns = df_all.columns.get_level_values(0)
            
        df_all = df_all[['Close', 'Volume']].dropna()
        target_dt = pd.to_datetime(target_date)
        
        # ğŸ›¡ï¸ ì² ì €í•œ ë¯¸ë˜ ë°ì´í„° ì°¨ë‹¨ (Train ë°ì´í„°ì…‹)
        df_train = df_all[df_all.index <= target_dt].copy()
        # ë¯¸ë˜ ì‹¤ì œ ë°ì´í„° (Test ë°ì´í„°ì…‹ - ë‚˜ì¤‘ì— ì˜¤ë²„ë ˆì´ìš©)
        df_future = df_all[df_all.index > target_dt].copy()
        
        closes = df_train['Close'].values
        volumes = df_train['Volume'].values
        n_days = len(closes)
        
        if n_days < 250: return None, "ì§€ì •í•˜ì‹  ë‚ ì§œ ì´ì „ì˜ ê³¼ê±° ë°ì´í„°ê°€ í•™ìŠµí•˜ê¸°ì— ë¶€ì¡±í•©ë‹ˆë‹¤."

        win = 20
        df_train['Slope_20'] = np.nan
        df_train['Sigma_20'] = np.nan
        df_train['Slope_60'] = np.nan
        
        for i in range(60, n_days):
            prices_20 = closes[i-win:i]
            prices_60 = closes[i-60:i]
            
            df_train.loc[df_train.index[i], 'Slope_20'] = calc_fast_slope(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
            df_train.loc[df_train.index[i], 'Sigma_20'] = calc_sigma(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
            df_train.loc[df_train.index[i], 'Slope_60'] = calc_fast_slope(prices_60, X_ARR_60, X_MEAN_60, X_VAR_SUM_60)

        df_train['Slope_Accel'] = df_train['Slope_20'] - df_train['Slope_20'].shift(1)
        df_train['Slope_Divergence'] = df_train['Slope_20'] - df_train['Slope_60']
        df_train['Drop_off_Shock'] = (df_train['Close'] / df_train['Close'].shift(win)) - 1.0
        df_train['Hist_Vol_20'] = df_train['Close'].pct_change().rolling(win).std() * np.sqrt(252)
        df_train['Skewness_20'] = df_train['Close'].pct_change().rolling(win).apply(skew, raw=True)
        df_train['Volume_Z'] = (df_train['Volume'] - df_train['Volume'].rolling(win).mean()) / df_train['Volume'].rolling(win).std()
        
        df_train['OBV'] = (np.sign(df_train['Close'].diff()) * df_train['Volume']).fillna(0).cumsum()
        df_train['OBV_Slope'] = df_train['OBV'].pct_change(win) * 100 
        
        ema_12 = df_train['Close'].ewm(span=12, adjust=False).mean()
        ema_26 = df_train['Close'].ewm(span=26, adjust=False).mean()
        df_train['MACD'] = ema_12 - ema_26
        df_train['MACD_Slope'] = df_train['MACD'] - df_train['MACD'].shift(1)
        
        df_train['Target_Slope_Next'] = df_train['Slope_20'].shift(-1)
        
        features = ['Sigma_20', 'Slope_20', 'Slope_60', 'Slope_Accel', 'Slope_Divergence', 
                    'Drop_off_Shock', 'Hist_Vol_20', 'Skewness_20', 'Volume_Z', 'OBV_Slope', 'MACD_Slope']
        
        ml_df = df_train.dropna(subset=features + ['Target_Slope_Next'])
        
        X_all = ml_df[features].values
        Y_all = ml_df['Target_Slope_Next'].values
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_all)
        
        model = RandomForestRegressor(n_estimators=200, max_depth=7, min_samples_leaf=5, random_state=42)
        model.fit(X_scaled, Y_all)
        
        y_pred_train = model.predict(X_scaled)
        residuals_std = np.std(Y_all - y_pred_train)
        
        # ---------------------------------------------------------
        # ğŸ“ˆ 3. AI ê°€ìƒ ì˜ˆì¸¡ ê¶¤ì  ìƒì„± (ë¯¸ë˜ ë°ì´í„°ë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœ)
        # ---------------------------------------------------------
        last_row = ml_df.iloc[-1]
        curr_state = {f: last_row[f] for f in features}
        
        pred_slopes = [curr_state['Slope_20']]
        pred_sigmas = [curr_state['Sigma_20']]
        pred_dates = [target_dt]
        
        np.random.seed(42) # ë¹„êµì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •
        
        current_date = target_dt
        for step in range(T):
            x_input = np.array([[curr_state[f] for f in features]])
            x_input_scaled = scaler.transform(x_input)
            
            base_next_slope = model.predict(x_input_scaled)[0]
            stochastic_shock = np.random.normal(0, residuals_std * 0.8)
            next_slope = base_next_slope + stochastic_shock
            
            curr_state['Slope_Accel'] = next_slope - curr_state['Slope_20']
            curr_state['Slope_20'] = next_slope
            curr_state['Slope_60'] = curr_state['Slope_60'] * 0.95 + next_slope * 0.05
            curr_state['Slope_Divergence'] = curr_state['Slope_20'] - curr_state['Slope_60']
            
            next_sigma = (curr_state['Sigma_20'] * 0.8) + (curr_state['Slope_Accel'] * 2.0) + np.random.normal(0, 0.2)
            curr_state['Sigma_20'] = next_sigma
            
            current_date = current_date + BDay(1)
            pred_dates.append(current_date)
            pred_slopes.append(curr_state['Slope_20'])
            pred_sigmas.append(curr_state['Sigma_20'])

        # ---------------------------------------------------------
        # ğŸ” 4. ì‹¤ì œ í˜„ì‹¤ ë°ì´í„° ì¶”ì¶œ (ì •ë‹µì§€ í™•ì¸)
        # ---------------------------------------------------------
        actual_slopes = [last_row['Slope_20']]
        actual_sigmas = [last_row['Sigma_20']]
        actual_dates = [target_dt]
        
        if not df_future.empty:
            # ë¯¸ë˜ ë°ì´í„°ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ Train + Future ê²°í•© (ì§€í‘œ ì—°ì†ì„±)
            df_eval = df_all.copy()
            df_eval['Slope_20'] = np.nan
            df_eval['Sigma_20'] = np.nan
            
            eval_closes = df_eval['Close'].values
            
            # target_date ì´í›„ì˜ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì‹œê·¸ë§ˆ/ìŠ¬ë¡œí”„ ê³„ì‚°
            future_indices = np.where(df_eval.index > target_dt)[0]
            take_t = min(T, len(future_indices))
            
            for k in range(take_t):
                idx = future_indices[k]
                prices_20 = eval_closes[idx-win:idx+1] # ê·¸ë‚  í¬í•¨ 20ì¼
                df_eval.loc[df_eval.index[idx], 'Slope_20'] = calc_fast_slope(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
                df_eval.loc[df_eval.index[idx], 'Sigma_20'] = calc_sigma(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
                
                actual_dates.append(df_eval.index[idx])
                actual_slopes.append(df_eval.loc[df_eval.index[idx], 'Slope_20'])
                actual_sigmas.append(df_eval.loc[df_eval.index[idx], 'Sigma_20'])

        res = {
            'T': T,
            'pred_dates': pred_dates,
            'pred_slopes': pred_slopes,
            'pred_sigmas': pred_sigmas,
            'actual_dates': actual_dates,
            'actual_slopes': actual_slopes,
            'actual_sigmas': actual_sigmas
        }
        return res, None

    except Exception as e:
        return None, f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ---------------------------------------------------------
# âš™ï¸ 5. í™”ë©´ ë Œë”ë§
# ---------------------------------------------------------
if run_btn:
    with st.spinner(f"ğŸ“¦ {target_date} ì‹œì ìœ¼ë¡œ ëŒì•„ê°€ AIë¥¼ í•™ìŠµì‹œí‚¤ê³ , í˜„ì‹¤ ë°ì´í„°ì™€ ë¹„êµ ì¤‘ì…ë‹ˆë‹¤..."):
        res, err = backtest_ai_prediction(target_ticker, target_date, target_t)
        
    if err:
        st.error(err)
    else:
        st.success(f"âœ… AI ì˜ˆì¸¡ vs í˜„ì‹¤ ê²€ì¦ ì™„ë£Œ! (í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼: {target_date})")
        
        # --- ìŠ¬ë¡œí”„(Slope) ë¹„êµ ì°¨íŠ¸ ---
        st.subheader(f"ğŸ“ˆ 1. ì¶”ì„¸ ê¸°ìš¸ê¸°(Slope) ê²€ì¦")
        st.markdown("> AIê°€ ì˜ˆìƒí•œ ê¸°ìš¸ê¸°ì˜ êº¾ì„(íŒŒë€ ì ì„ )ê³¼ ì‹¤ì œ ì‹œì¥ì˜ ê¸°ìš¸ê¸° ë³€í™”(íŒŒë€ ì‹¤ì„ )ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
        
        fig_slope = go.Figure()
        
        fig_slope.add_trace(go.Scatter(
            x=res['pred_dates'], y=res['pred_slopes'], mode='lines+markers',
            line=dict(color='#3498db', width=2, dash='dot'), name='AI ì˜ˆìƒ ìŠ¬ë¡œí”„'
        ))
        
        if len(res['actual_dates']) > 1:
            fig_slope.add_trace(go.Scatter(
                x=res['actual_dates'], y=res['actual_slopes'], mode='lines+markers',
                line=dict(color='#2980b9', width=4), name='ì‹¤ì œ í˜„ì‹¤ ìŠ¬ë¡œí”„'
            ))
            
        fig_slope.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
        fig_slope.update_layout(hovermode="x unified", height=350, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="Slope (%)")
        st.plotly_chart(fig_slope, use_container_width=True)
        
        st.markdown("---")
        
        # --- ì‹œê·¸ë§ˆ(Sigma) ë¹„êµ ì°¨íŠ¸ ---
        st.subheader(f"ğŸ“‰ 2. ì‹œê·¸ë§ˆ(Sigma) ë³µì›ë ¥ ê²€ì¦")
        st.markdown("> AIê°€ ì˜ˆìƒí•œ ì‹œê·¸ë§ˆì˜ í‰ê·  íšŒê·€(ì£¼í™© ì ì„ )ì™€ ì‹¤ì œ ê³ ë¬´ì¤„ì˜ íŠ•ê¹€(ì£¼í™© ì‹¤ì„ )ì„ ë¹„êµí•©ë‹ˆë‹¤.")
        
        fig_sigma = go.Figure()
        
        fig_sigma.add_trace(go.Scatter(
            x=res['pred_dates'], y=res['pred_sigmas'], mode='lines+markers',
            line=dict(color='#e67e22', width=2, dash='dot'), name='AI ì˜ˆìƒ ì‹œê·¸ë§ˆ'
        ))
        
        if len(res['actual_dates']) > 1:
            fig_sigma.add_trace(go.Scatter(
                x=res['actual_dates'], y=res['actual_sigmas'], mode='lines+markers',
                line=dict(color='#d35400', width=4), name='ì‹¤ì œ í˜„ì‹¤ ì‹œê·¸ë§ˆ'
            ))
            
        fig_sigma.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
        fig_sigma.update_layout(hovermode="x unified", height=350, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="Sigma (ì´ê²©ë„)")
        st.plotly_chart(fig_sigma, use_container_width=True)
