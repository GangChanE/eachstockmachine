import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from scipy.stats import skew, kurtosis
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestClassifier # ğŸŒŸ ë©”íƒ€ ëª¨ë¸ìš©
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
from pandas.tseries.offsets import BDay
import warnings

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# âš™ï¸ 0. ê³ ì† ì—°ì‚° ë° ì—­ì‚°(Reverse Engineering) í•¨ìˆ˜
# ---------------------------------------------------------
def get_linear_params(win):
    X = np.arange(win)
    X_mean = np.mean(X)
    X_var_sum = np.sum((X - X_mean)**2)
    return X, X_mean, X_var_sum

def calc_fast_slope(prices, X, X_mean, X_var_sum):
    y_mean = np.mean(prices)
    slope = np.sum((X - X_mean) * (prices - y_mean)) / X_var_sum
    current_price = prices[-1]
    return (slope / current_price) * 100 if current_price > 0 else 0.0

def calc_sigma(prices, X, X_mean, X_var_sum):
    y_mean = np.mean(prices)
    slope = np.sum((X - X_mean) * (prices - y_mean)) / X_var_sum
    intercept = y_mean - slope * X_mean
    trend_line = slope * X + intercept
    std = np.std(prices - trend_line)
    return (prices[-1] - trend_line[-1]) / std if std > 0 else 0.0

def reverse_calculate_price(prev_19_prices, target_slope_pct):
    """
    [í•µì‹¬ ìˆ˜í•™ ë¡œì§] ê³¼ê±° 19ì¼ì˜ ë°ì´í„°ì™€ ëª©í‘œ ìŠ¬ë¡œí”„(%)ë¥¼ í†µí•´ ë‚´ì¼ì˜ ì£¼ê°€ë¥¼ ì—­ì‚°í•©ë‹ˆë‹¤.
    P_next = K / (6.65 * Slope_pct - 10.5)
    """
    K = np.sum((np.arange(19) - 9.5) * prev_19_prices)
    denom = 6.65 * target_slope_pct - 10.5
    
    # ë¶„ëª¨ê°€ 0ì— ìˆ˜ë ´í•˜ì—¬ ê°€ê²©ì´ í­ë°œí•˜ëŠ” íŠ¹ì´ì (Singularity) ë°©ì§€
    if abs(denom) < 0.01:
        denom = -0.01 if denom < 0 else 0.01
        
    raw_price = K / denom
    last_price = prev_19_prices[-1]
    
    # í•œêµ­ ì‹œì¥ ìƒí•˜í•œê°€ 30% ë£° ì ìš© (ìˆ˜í•™ì  ì˜¤ë¥˜ë¡œ ì¸í•œ ìŒìˆ˜ ê°€ê²© ì™„ë²½ ì°¨ë‹¨)
    return np.clip(raw_price, last_price * 0.7, last_price * 1.3)

# ---------------------------------------------------------
# âš™ï¸ 1. UI ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(page_title="Quantum Oracle V24", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® The Quantum Oracle V24: ë©”íƒ€ ì—­ì‚° & Tì¼ ìµœì í™”ê¸°")
st.markdown("""
AIê°€ ì˜ˆì¸¡í•œ ìŠ¬ë¡œí”„/ì‹œê·¸ë§ˆë¥¼ í†µí•´ **ë¯¸ë˜ ì£¼ê°€ë¥¼ ì—­ì‚°**í•©ë‹ˆë‹¤.  
ê³¼ê±° 100ì¼ê°„ì˜ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•´ 1ì¼~20ì¼ ì¤‘ **ê°€ì¥ ì˜ˆì¸¡ ì ì¤‘ë¥ ì´ ë†’ì€ ë³´ìœ ê¸°ê°„(T)**ì˜ ìˆœìœ„ë¥¼ ë§¤ê¸°ê³ , **ë©”íƒ€ ëª¨ë¸(Meta-AI)**ì´ ì˜¤ëŠ˜ì˜ ì¥ì„¸ì— ë§ëŠ” ìµœì ì˜ Të¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
""")

with st.sidebar:
    st.header("âš™ï¸ í•˜ì´í¼ íƒ€ì„ë¨¸ì‹  ì„¤ì •")
    target_ticker = st.text_input("ì¢…ëª© ì½”ë“œ (ìš°ëŸ‰ì£¼/ETF ê¶Œì¥)", value="069500.KS")
    target_date = st.date_input("í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (íƒ€ì„ë¨¸ì‹  íƒ‘ìŠ¹ì¼)")
    run_btn = st.button("ğŸš€ ì „ì²´ T ìˆœìœ„ ë¶„ì„ ë° ë©”íƒ€ ì¶”ì²œ", type="primary")

# ---------------------------------------------------------
# âš™ï¸ 2. AI í•™ìŠµ, ì—­ì‚° ê²€ì¦ ë° ë©”íƒ€ ëª¨ë¸ í›ˆë ¨
# ---------------------------------------------------------
@st.cache_data(show_spinner=False, ttl=3600)
def analyze_optimal_horizon(ticker, target_date):
    try:
        # ë°ì´í„° ë¡œë“œ ë° íƒ€ì„ì¡´ ì œê±°
        df_target = yf.download(ticker, start="2010-01-01", progress=False)
        df_vix = yf.download("^VIX", start="2010-01-01", progress=False)
        df_spx = yf.download("^GSPC", start="2010-01-01", progress=False)
        
        if df_target.empty: return None, "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨."
        
        for d in [df_target, df_vix, df_spx]:
            if isinstance(d.columns, pd.MultiIndex): d.columns = d.columns.get_level_values(0)

        df_target.index = df_target.index.tz_localize(None)
        df_vix.index = df_vix.index.tz_localize(None)
        df_spx.index = df_spx.index.tz_localize(None)

        df = pd.DataFrame(index=df_target.index)
        df['Close'] = df_target['Close']
        df['Volume'] = df_target['Volume']
        
        df = df.join(df_vix[['Close']].rename(columns={'Close': 'VIX'}), how='left')
        df = df.join(df_spx[['Close']].rename(columns={'Close': 'SPX'}), how='left')
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        target_dt = pd.to_datetime(target_date).tz_localize(None)
        df_train = df[df.index <= target_dt].copy()
        df_future = df[df.index > target_dt].copy()
        
        closes = df_train['Close'].values
        n_days = len(closes)
        if n_days < 300: return None, "ê³¼ê±° ë°ì´í„° ë¶€ì¡±."

        X_20, X_m_20, X_v_20 = get_linear_params(20)
        df_train['Slope_20'] = np.nan
        df_train['Sigma_20'] = np.nan
        
        for i in range(20, n_days):
            prices_20 = closes[i-20+1 : i+1]
            df_train.loc[df_train.index[i], 'Slope_20'] = calc_fast_slope(prices_20, X_20, X_m_20, X_v_20)
            df_train.loc[df_train.index[i], 'Sigma_20'] = calc_sigma(prices_20, X_20, X_m_20, X_v_20)

        # í”¼ì²˜ ì„¤ê³„
        df_train['Slope_Accel'] = df_train['Slope_20'] - df_train['Slope_20'].shift(1)
        df_train['VIX_Change'] = df_train['VIX'].pct_change(5).fillna(0)
        
        df_train['Target_Slope_Next'] = df_train['Slope_20'].shift(-1)
        features = ['Sigma_20', 'Slope_20', 'Slope_Accel', 'VIX_Change']
        
        last_row = df_train.iloc[-1]
        ml_df = df_train.dropna(subset=features + ['Target_Slope_Next'])
        
        X_all = ml_df[features].values
        Y_slope = ml_df['Target_Slope_Next'].values
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_all)
        
        model_slope = XGBRegressor(n_estimators=100, max_depth=3, random_state=42, n_jobs=-1)
        model_slope.fit(X_scaled, Y_slope)

        # ---------------------------------------------------------
        # ğŸŒŸ [ê²€ì¦ í˜ì´ì¦ˆ] ê³¼ê±° 100ì¼ê°„ 1~20ì¼ ì£¼ê°€ ì—­ì‚° ì‹œë®¬ë ˆì´ì…˜
        # ---------------------------------------------------------
        # ë¯¸ë˜ë¥¼ 20ì¼ ì´ìƒ ë“¤ì—¬ë‹¤ë´ì•¼ í•˜ë¯€ë¡œ, í‰ê°€ ê¸°ê°„ì€ -120ì¼ë¶€í„° -20ì¼ê¹Œì§€ë¡œ í•œì • (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
        eval_indices = range(len(ml_df) - 120, len(ml_df) - 20)
        
        error_matrix = np.zeros((len(eval_indices), 20)) # (100ì¼, T=20)
        best_t_labels = []
        meta_features = []
        
        for row_idx, i in enumerate(eval_indices):
            curr_state = {f: ml_df.iloc[i][f] for f in features}
            
            # ë©”íƒ€ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ í•´ë‹¹ ë‚ ì§œì˜ ì‹œê·¸ë§ˆì™€ ìŠ¬ë¡œí”„ ì €ì¥
            meta_features.append([curr_state['Sigma_20'], curr_state['Slope_20']])
            
            # ì£¼ê°€ ì—­ì‚°ì„ ìœ„í•œ ê³¼ê±° 20ì¼ ê¸°ë¡ (ë¦¬ìŠ¤íŠ¸ ë³µì‚¬)
            hist_prices = list(closes[i-19 : i+1])
            
            sim_prices = []
            for step in range(20):
                x_in = scaler.transform([[curr_state[f] for f in features]])
                next_slope = model_slope.predict(x_in)[0]
                
                # ğŸŒŸ ìˆ˜í•™ì  ì£¼ê°€ ì—­ì‚°!
                prev_19 = hist_prices[-19:]
                next_price = reverse_calculate_price(prev_19, next_slope)
                sim_prices.append(next_price)
                hist_prices.append(next_price)
                
                # ê°€ìƒì˜ ë‚´ì¼ì„ ìœ„í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
                curr_state['Slope_Accel'] = next_slope - curr_state['Slope_20']
                curr_state['Slope_20'] = next_slope
                # Sigma ë“±ì€ ìƒìˆ˜ ë˜ëŠ” ë‹¨ìˆœ ê°ì‡ ë¡œ ì²˜ë¦¬í•˜ì—¬ ì—­ì‚°ì— ì§‘ì¤‘
                curr_state['Sigma_20'] = curr_state['Sigma_20'] * 0.9 

            # ì •ë‹µì§€ì™€ ë¹„êµ (ì‹¤ì œ ì£¼ê°€)
            actual_prices = closes[i+1 : i+21]
            # MAPE (í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨) ê³„ì‚°
            errors = np.abs(np.array(sim_prices) - actual_prices) / actual_prices * 100
            error_matrix[row_idx, :] = errors
            
            # ì´ ë‚ ì§œì— ê°€ì¥ ì—ëŸ¬ê°€ ì ì—ˆë˜ ìµœê³ ì˜ T ì°¾ê¸°
            best_t_labels.append(np.argmin(errors) + 1)

        # ---------------------------------------------------------
        # ğŸ“ˆ ì „ì²´ ê¸°ê°„ T ìˆœìœ„ ë§¤ê¸°ê¸°
        # ---------------------------------------------------------
        mean_errors_per_t = np.mean(error_matrix, axis=0)
        ranking_indices = np.argsort(mean_errors_per_t) # ì—ëŸ¬ê°€ ì‘ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        
        t_rankings = []
        for rank, t_idx in enumerate(ranking_indices):
            t_rankings.append({
                'Rank': rank + 1,
                'T_days': t_idx + 1,
                'Error_Pct': mean_errors_per_t[t_idx]
            })

        # ---------------------------------------------------------
        # ğŸ§  ë©”íƒ€ ëª¨ë¸(Meta-AI) í•™ìŠµ: ì˜¤ëŠ˜ì˜ ìƒíƒœì— ë§ëŠ” T ì¶”ì²œ
        # ---------------------------------------------------------
        meta_clf = RandomForestClassifier(n_estimators=50, max_depth=4, random_state=42)
        meta_clf.fit(meta_features, best_t_labels)
        
        # í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ì˜ ìƒíƒœë¡œ ìµœì ì˜ T ì˜ˆì¸¡
        today_meta_feature = [[last_row['Sigma_20'], last_row['Slope_20']]]
        recommended_t = meta_clf.predict(today_meta_feature)[0]

        # ---------------------------------------------------------
        # ğŸ”® íƒ€ê²Ÿ ë‚ ì§œ ì‹¤ì „ ì‹œë®¬ë ˆì´ì…˜ (ì¶”ì²œëœ Tê¹Œì§€)
        # ---------------------------------------------------------
        curr_state = {f: last_row[f] for f in features}
        hist_prices = list(closes[-20:])
        sim_prices = []
        sim_dates = []
        
        c_date = target_dt
        for step in range(20):
            x_in = scaler.transform([[curr_state[f] for f in features]])
            next_slope = model_slope.predict(x_in)[0]
            
            prev_19 = hist_prices[-19:]
            next_price = reverse_calculate_price(prev_19, next_slope)
            
            c_date += BDay(1)
            sim_prices.append(next_price)
            sim_dates.append(c_date)
            hist_prices.append(next_price)
            
            curr_state['Slope_Accel'] = next_slope - curr_state['Slope_20']
            curr_state['Slope_20'] = next_slope
            curr_state['Sigma_20'] = curr_state['Sigma_20'] * 0.9

        # ì‹¤ì œ ë¯¸ë˜ ë°ì´í„°
        actual_dates = []
        actual_prices = []
        if not df_future.empty:
            df_eval = df.copy()
            future_indices = np.where(df.index > target_dt)[0]
            take_t = min(20, len(future_indices))
            for k in range(take_t):
                actual_dates.append(df.index[future_indices[k]])
                actual_prices.append(df['Close'].iloc[future_indices[k]])

        res = {
            't_rankings': t_rankings,
            'recommended_t': int(recommended_t),
            'target_date': target_dt,
            'curr_sigma': last_row['Sigma_20'],
            'curr_slope': last_row['Slope_20'],
            'sim_dates': sim_dates,
            'sim_prices': sim_prices,
            'actual_dates': actual_dates,
            'actual_prices': actual_prices
        }
        return res, None

    except Exception as e:
        return None, f"ë©”íƒ€ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ---------------------------------------------------------
# âš™ï¸ 3. í™”ë©´ ë Œë”ë§
# ---------------------------------------------------------
if run_btn:
    with st.spinner(f"ğŸ“¦ ê³¼ê±° 100ì¼ ì¹˜ ê°€ìƒ ì—­ì‚° ë°±í…ŒìŠ¤íŠ¸ì™€ ë©”íƒ€ AI(Meta-AI)ë¥¼ í›ˆë ¨ ì¤‘ì…ë‹ˆë‹¤..."):
        res, err = analyze_optimal_horizon(target_ticker, target_date)
        
    if err:
        st.error(err)
    else:
        st.success(f"âœ… ì£¼ê°€ ì—­ì‚° ë° ìµœì  T ë¶„ì„ ì™„ë£Œ!")
        
        # --- ë©”íƒ€ ëª¨ë¸ ì¶”ì²œ ---
        st.subheader("ğŸ§  1. ë©”íƒ€ AI (Meta-Model)ì˜ ì‹¤ì‹œê°„ ì¶”ì²œ")
        st.info(f"**í˜„ì¬ ìƒíƒœ:** ì‹œê·¸ë§ˆ {res['curr_sigma']:.2f} / ê¸°ìš¸ê¸° {res['curr_slope']:.2f}%\n\n"
                f"ë©”íƒ€ AI ë¶„ì„ ê²°ê³¼, ì˜¤ëŠ˜ ê°™ì€ ì¥ì„¸ì—ì„œëŠ” **[ T = {res['recommended_t']}ì¼ ]** ë’¤ì— ë§¤ë„í•˜ëŠ” ê²ƒì´ ì—­ì‚¬ì ìœ¼ë¡œ ê°€ì¥ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ì•˜ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        # --- ì „ì²´ T ë­í‚¹ (1~20ìœ„) ---
        st.subheader("ğŸ“Š 2. ëª¨ë“  ì¥ì„¸ í¬í•¨: Tì¼ ë³´ìœ ê¸°ê°„ ì •í™•ë„ ë­í‚¹ (Top 10)")
        df_rank = pd.DataFrame(res['t_rankings'])
        
        fig_bar = go.Figure(go.Bar(
            x=df_rank['T_days'][:10].astype(str) + "ì¼", 
            y=df_rank['Error_Pct'][:10],
            marker=dict(color='rgba(52, 152, 219, 0.8)')
        ))
        fig_bar.update_layout(height=350, yaxis_title="ì—­ì‚° ì£¼ê°€ ì˜¤ì°¨ìœ¨ (%) - ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ", xaxis_title="ë³´ìœ  ê¸°ê°„ (T)")
        st.plotly_chart(fig_bar, use_container_width=True)
        
        st.markdown("---")
        
        # --- ì£¼ê°€ ê¶¤ì  ì˜¤ë²„ë ˆì´ ---
        st.subheader(f"ğŸ“ˆ 3. ì—­ì‚°ëœ ì£¼ê°€ ê¶¤ì  vs ì‹¤ì œ ì£¼ê°€ (ìµœëŒ€ 20ì¼)")
        st.markdown("> AIê°€ ìŠ¬ë¡œí”„ë¥¼ ì˜ˆì¸¡í•˜ê³ , ëŒ€ìˆ˜í•™ì  ì—­ì‚° ê³µì‹ì„ í†µí•´ ë½‘ì•„ë‚¸ **'ê°€ìƒì˜ ë‚´ì¼ ì£¼ê°€(ì ì„ )'**ì…ë‹ˆë‹¤.")
        
        fig_price = go.Figure()
        
        fig_price.add_trace(go.Scatter(
            x=res['sim_dates'], y=res['sim_prices'], mode='lines+markers',
            line=dict(color='#e74c3c', width=3, dash='dot'), name='ì—­ì‚° ì˜ˆì¸¡ ì£¼ê°€'
        ))
        
        if len(res['actual_dates']) > 0:
            fig_price.add_trace(go.Scatter(
                x=res['actual_dates'], y=res['actual_prices'], mode='lines+markers',
                line=dict(color='#2c3e50', width=4), name='ì‹¤ì œ ì‹œì¥ ì£¼ê°€'
            ))
            
        # ë©”íƒ€ AIê°€ ì¶”ì²œí•œ ë‚ ì§œì— ì„¸ë¡œì„  ê¸‹ê¸°
        if res['recommended_t'] <= len(res['sim_dates']):
            rec_date = res['sim_dates'][res['recommended_t'] - 1]
            fig_price.add_vline(x=rec_date, line_dash="dash", line_color="green", annotation_text=f"ì¶”ì²œ ë§¤ë„ì¼ (T={res['recommended_t']})")

        fig_price.update_layout(hovermode="x unified", height=450, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="ì£¼ê°€ (ì›)")
        st.plotly_chart(fig_price, use_container_width=True)
