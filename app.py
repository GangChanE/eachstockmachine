import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from scipy.stats import linregress, skew
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
from pandas.tseries.offsets import BDay
import warnings

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# âš™ï¸ 0. ê³ ì† ì—°ì‚° í•¨ìˆ˜ (ë°°ì—´ ê¸¸ì´ 20ìœ¼ë¡œ ì—„ê²©íˆ í†µì œ)
# ---------------------------------------------------------
X_ARR_20 = np.arange(20)
X_MEAN_20 = 9.5
X_VAR_SUM_20 = 665.0 

X_ARR_60 = np.arange(60)
X_MEAN_60 = 29.5
X_VAR_SUM_60 = 17990.0

def calc_fast_slope(prices, X_ARR, X_MEAN, X_VAR_SUM):
    y_mean = np.mean(prices)
    slope = np.sum((X_ARR - X_MEAN) * (prices - y_mean)) / X_VAR_SUM
    current_price = prices[-1]
    return (slope / current_price) * 100 if current_price > 0 else 0.0

def calc_sigma(prices, X_ARR, X_MEAN, X_VAR_SUM):
    y_mean = np.mean(prices)
    slope = np.sum((X_ARR - X_MEAN) * (prices - y_mean)) / X_VAR_SUM
    intercept = y_mean - slope * X_MEAN
    trend_line = slope * X_ARR + intercept
    std = np.std(prices - trend_line)
    return (prices[-1] - trend_line[-1]) / std if std > 0 else 0.0

# ---------------------------------------------------------
# âš™ï¸ 1. UI ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(page_title="Quantum Oracle V22.1", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® The Quantum Oracle V22.1: ë¬´ê²°ì  AI ê²€ì¦ê¸°")
st.markdown("""
ê³¼ê±° íŠ¹ì • ë‚ ì§œê¹Œì§€ì˜ ë°ì´í„°ë§Œìœ¼ë¡œ AIë¥¼ í•™ìŠµì‹œí‚¤ê³ , ë¯¸ë˜ë¥¼ ì™„ë²½íˆ ê°€ë¦° ìƒíƒœì—ì„œ Tì¼ ê°„ì˜ 'ìŠ¬ë¡œí”„ & ì‹œê·¸ë§ˆ' ê¶¤ì ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.  
ê·¸ í›„ **ì‹¤ì œ ì‹œì¥ì—ì„œ ì¼ì–´ë‚œ í˜„ì‹¤ ê¶¤ì ê³¼ ì˜¤ë²„ë ˆì´(Overlay)**í•˜ì—¬ ëª¨ë¸ì˜ ë‹¨ê¸° ìŠ¤ìœ™ ì •í™•ë„ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
""")

with st.sidebar:
    st.header("âš™ï¸ íƒ€ì„ë¨¸ì‹  ê²€ì¦ ì„¤ì •")
    target_ticker = st.text_input("ì¢…ëª© ì½”ë“œ (í‹°ì»¤)", value="069500.KS")
    target_date = st.date_input("í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ (íƒ€ì„ë¨¸ì‹  íƒ‘ìŠ¹ì¼)")
    target_t = st.number_input("ë‹¨ê¸° ì˜ˆì¸¡ ê¸°ê°„ (Tì¼)", min_value=1, max_value=60, value=10, step=1)
    run_btn = st.button("ğŸš€ ì˜ˆì¸¡ vs í˜„ì‹¤ ë¹„êµ ê°€ë™", type="primary")

# ---------------------------------------------------------
# âš™ï¸ 2. AI í•™ìŠµ ë° ê²€ì¦ ì—”ì§„
# ---------------------------------------------------------
@st.cache_data(show_spinner=False, ttl=3600)
def backtest_ai_prediction(ticker, target_date, T):
    try:
        raw = yf.download(ticker, start="2012-01-01", progress=False)
        if raw.empty: return None, "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨."
            
        df_all = raw.copy()
        if isinstance(df_all.columns, pd.MultiIndex):
            df_all.columns = df_all.columns.get_level_values(0)
            
        df_all = df_all[['Close', 'Volume']].dropna()
        target_dt = pd.to_datetime(target_date)
        
        # ğŸ›¡ï¸ ë¯¸ë˜ ë°ì´í„° ì°¨ë‹¨
        df_train = df_all[df_all.index <= target_dt].copy()
        df_future = df_all[df_all.index > target_dt].copy()
        
        closes = df_train['Close'].values
        n_days = len(closes)
        
        if n_days < 250: return None, "ì§€ì •í•˜ì‹  ë‚ ì§œ ì´ì „ì˜ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

        win = 20
        df_train['Slope_20'] = np.nan
        df_train['Sigma_20'] = np.nan
        df_train['Slope_60'] = np.nan
        
        # ğŸŒŸ ë²„ê·¸ ìˆ˜ì •: i-win+1 ë¶€í„° i+1ê¹Œì§€ ì •í™•íˆ 20ê°œ ì¶”ì¶œ
        for i in range(60, n_days):
            prices_20 = closes[i-win+1 : i+1]
            prices_60 = closes[i-60+1 : i+1]
            
            df_train.loc[df_train.index[i], 'Slope_20'] = calc_fast_slope(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
            df_train.loc[df_train.index[i], 'Sigma_20'] = calc_sigma(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
            df_train.loc[df_train.index[i], 'Slope_60'] = calc_fast_slope(prices_60, X_ARR_60, X_MEAN_60, X_VAR_SUM_60)

        # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        df_train['Slope_Accel'] = df_train['Slope_20'] - df_train['Slope_20'].shift(1)
        df_train['Slope_Divergence'] = df_train['Slope_20'] - df_train['Slope_60']
        df_train['Drop_off_Shock'] = (df_train['Close'] / df_train['Close'].shift(win)) - 1.0
        df_train['Hist_Vol_20'] = df_train['Close'].pct_change().rolling(win).std() * np.sqrt(252)
        df_train['Skewness_20'] = df_train['Close'].pct_change().rolling(win).apply(skew, raw=True)
        df_train['Volume_Z'] = (df_train['Volume'] - df_train['Volume'].rolling(win).mean()) / df_train['Volume'].rolling(win).std()
        
        df_train['OBV'] = (np.sign(df_train['Close'].diff()) * df_train['Volume']).fillna(0).cumsum()
        df_train['OBV_Slope'] = df_train['OBV'].pct_change(win) * 100 
        
        ema_12 = df_train['Close'].ewm(span=12, adjust=False).mean()
        ema_26 = df_train['Close'].ewm(span=26, adjust=False).mean()
        df_train['MACD'] = ema_12 - ema_26
        df_train['MACD_Slope'] = df_train['MACD'] - df_train['MACD'].shift(1)
        
        # íƒ€ê²Ÿ ì„¤ì • (ë‚´ì¼ì˜ ìŠ¬ë¡œí”„)
        df_train['Target_Slope_Next'] = df_train['Slope_20'].shift(-1)
        
        features = ['Sigma_20', 'Slope_20', 'Slope_60', 'Slope_Accel', 'Slope_Divergence', 
                    'Drop_off_Shock', 'Hist_Vol_20', 'Skewness_20', 'Volume_Z', 'OBV_Slope', 'MACD_Slope']
        
        # ğŸŒŸ ë²„ê·¸ ìˆ˜ì •: ì˜ˆì¸¡ì˜ ì¶œë°œì ì´ ë  'í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼ ë‹¹ì¼(last_row)' ì¶”ì¶œ
        # (Target_Slope_NextëŠ” NaNì´ê² ì§€ë§Œ, FeaturesëŠ” ëª¨ë‘ ë“¤ì–´ìˆìŒ)
        last_row = df_train.iloc[-1]
        
        # AI í•™ìŠµìš© ë°ì´í„° (ë‚´ì¼ì˜ ì •ë‹µì´ ì—†ëŠ” ë§ˆì§€ë§‰ ë‚ ì€ ì œì™¸í•˜ê³  í•™ìŠµ)
        ml_df = df_train.dropna(subset=features + ['Target_Slope_Next'])
        
        X_all = ml_df[features].values
        Y_all = ml_df['Target_Slope_Next'].values
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_all)
        
        model = RandomForestRegressor(n_estimators=200, max_depth=7, min_samples_leaf=5, random_state=42)
        model.fit(X_scaled, Y_all)
        
        y_pred_train = model.predict(X_scaled)
        residuals_std = np.std(Y_all - y_pred_train)
        
        # ---------------------------------------------------------
        # ğŸ“ˆ 3. AI ê°€ìƒ ì˜ˆì¸¡ ê¶¤ì  ìƒì„±
        # ---------------------------------------------------------
        curr_state = {f: last_row[f] for f in features}
        
        pred_slopes = [curr_state['Slope_20']]
        pred_sigmas = [curr_state['Sigma_20']]
        pred_dates = [df_train.index[-1]] # ì •í™•íˆ ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚ ì§œë¶€í„° ì‹œì‘
        
        np.random.seed(42) 
        
        current_date = df_train.index[-1]
        for step in range(T):
            x_input = np.array([[curr_state[f] for f in features]])
            x_input_scaled = scaler.transform(x_input)
            
            base_next_slope = model.predict(x_input_scaled)[0]
            stochastic_shock = np.random.normal(0, residuals_std * 0.8)
            next_slope = base_next_slope + stochastic_shock
            
            curr_state['Slope_Accel'] = next_slope - curr_state['Slope_20']
            curr_state['Slope_20'] = next_slope
            curr_state['Slope_60'] = curr_state['Slope_60'] * 0.95 + next_slope * 0.05
            curr_state['Slope_Divergence'] = curr_state['Slope_20'] - curr_state['Slope_60']
            
            next_sigma = (curr_state['Sigma_20'] * 0.8) + (curr_state['Slope_Accel'] * 2.0) + np.random.normal(0, 0.2)
            curr_state['Sigma_20'] = next_sigma
            
            current_date = current_date + BDay(1)
            pred_dates.append(current_date)
            pred_slopes.append(curr_state['Slope_20'])
            pred_sigmas.append(curr_state['Sigma_20'])

        # ---------------------------------------------------------
        # ğŸ” 4. ì‹¤ì œ í˜„ì‹¤ ë°ì´í„° ì¶”ì¶œ (ì •ë‹µì§€ í™•ì¸)
        # ---------------------------------------------------------
        actual_slopes = [last_row['Slope_20']]
        actual_sigmas = [last_row['Sigma_20']]
        actual_dates = [df_train.index[-1]]
        
        if not df_future.empty:
            df_eval = df_all.copy()
            eval_closes = df_eval['Close'].values
            
            future_indices = np.where(df_eval.index > target_dt)[0]
            take_t = min(T, len(future_indices))
            
            # ğŸŒŸ ë²„ê·¸ ìˆ˜ì •: ì¸ë±ì‹± ì—ëŸ¬(21ê°œ ì¶”ì¶œ) ë°©ì§€ë¥¼ ìœ„í•´ ì •í™•íˆ 20ê°œë§Œ ìŠ¬ë¼ì´ì‹±
            for k in range(take_t):
                idx = future_indices[k]
                prices_20 = eval_closes[idx-win+1 : idx+1] 
                
                real_slope = calc_fast_slope(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
                real_sigma = calc_sigma(prices_20, X_ARR_20, X_MEAN_20, X_VAR_SUM_20)
                
                actual_dates.append(df_eval.index[idx])
                actual_slopes.append(real_slope)
                actual_sigmas.append(real_sigma)

        res = {
            'T': T,
            'pred_dates': pred_dates,
            'pred_slopes': pred_slopes,
            'pred_sigmas': pred_sigmas,
            'actual_dates': actual_dates,
            'actual_slopes': actual_slopes,
            'actual_sigmas': actual_sigmas
        }
        return res, None

    except Exception as e:
        return None, f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ---------------------------------------------------------
# âš™ï¸ 5. í™”ë©´ ë Œë”ë§
# ---------------------------------------------------------
if run_btn:
    with st.spinner(f"ğŸ“¦ {target_date} ì‹œì ìœ¼ë¡œ ëŒì•„ê°€ 11ê°œ ë‹¤ë³€ëŸ‰ AIë¥¼ í•™ìŠµì‹œí‚¤ê³ , í˜„ì‹¤ ë°ì´í„°ì™€ ë¹„êµ ì¤‘ì…ë‹ˆë‹¤..."):
        res, err = backtest_ai_prediction(target_ticker, target_date, target_t)
        
    if err:
        st.error(err)
    else:
        st.success(f"âœ… AI ì˜ˆì¸¡ vs í˜„ì‹¤ ê²€ì¦ ì™„ë£Œ! (í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼: {target_date})")
        
        # --- ìŠ¬ë¡œí”„(Slope) ë¹„êµ ì°¨íŠ¸ ---
        st.subheader(f"ğŸ“ˆ 1. ì¶”ì„¸ ê¸°ìš¸ê¸°(Slope) ê²€ì¦")
        st.markdown("> AIê°€ ì˜ˆìƒí•œ ê¸°ìš¸ê¸°ì˜ êº¾ì„(íŒŒë€ ì ì„ )ê³¼ ì‹¤ì œ ì‹œì¥ì˜ ê¸°ìš¸ê¸° ë³€í™”(íŒŒë€ ì‹¤ì„ )ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.")
        
        fig_slope = go.Figure()
        
        fig_slope.add_trace(go.Scatter(
            x=res['pred_dates'], y=res['pred_slopes'], mode='lines+markers',
            line=dict(color='#3498db', width=3, dash='dot'), name='AI ì˜ˆìƒ ìŠ¬ë¡œí”„'
        ))
        
        if len(res['actual_dates']) > 1:
            fig_slope.add_trace(go.Scatter(
                x=res['actual_dates'], y=res['actual_slopes'], mode='lines+markers',
                line=dict(color='#2c3e50', width=4), name='ì‹¤ì œ í˜„ì‹¤ ìŠ¬ë¡œí”„ (Reality)'
            ))
            
        fig_slope.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
        fig_slope.update_layout(hovermode="x unified", height=400, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="Slope (%)")
        st.plotly_chart(fig_slope, use_container_width=True)
        
        st.markdown("---")
        
        # --- ì‹œê·¸ë§ˆ(Sigma) ë¹„êµ ì°¨íŠ¸ ---
        st.subheader(f"ğŸ“‰ 2. ì‹œê·¸ë§ˆ(Sigma) ë³µì›ë ¥ ê²€ì¦")
        st.markdown("> AIê°€ ì˜ˆìƒí•œ ì‹œê·¸ë§ˆì˜ í‰ê·  íšŒê·€(ì£¼í™© ì ì„ )ì™€ ì‹¤ì œ ê³ ë¬´ì¤„ì˜ íŠ•ê¹€(ì£¼í™© ì‹¤ì„ )ì„ ë¹„êµí•©ë‹ˆë‹¤.")
        
        fig_sigma = go.Figure()
        
        fig_sigma.add_trace(go.Scatter(
            x=res['pred_dates'], y=res['pred_sigmas'], mode='lines+markers',
            line=dict(color='#e67e22', width=3, dash='dot'), name='AI ì˜ˆìƒ ì‹œê·¸ë§ˆ'
        ))
        
        if len(res['actual_dates']) > 1:
            fig_sigma.add_trace(go.Scatter(
                x=res['actual_dates'], y=res['actual_sigmas'], mode='lines+markers',
                line=dict(color='#d35400', width=4), name='ì‹¤ì œ í˜„ì‹¤ ì‹œê·¸ë§ˆ (Reality)'
            ))
            
        fig_sigma.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
        fig_sigma.update_layout(hovermode="x unified", height=400, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="Sigma (ì´ê²©ë„)")
        st.plotly_chart(fig_sigma, use_container_width=True)
