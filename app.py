import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from scipy.stats import skew, kurtosis
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
from pandas.tseries.offsets import BDay
import warnings

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# âš™ï¸ 0. ê³ ì† ì—°ì‚° ë° ì—­ì‚° ì—”ì§„
# ---------------------------------------------------------
def get_linear_params(win):
    X = np.arange(win)
    X_mean = np.mean(X)
    X_var_sum = np.sum((X - X_mean)**2)
    return X, X_mean, X_var_sum

def calc_fast_slope(prices, X, X_mean, X_var_sum):
    y_mean = np.mean(prices)
    slope = np.sum((X - X_mean) * (prices - y_mean)) / X_var_sum
    current_price = prices[-1]
    return (slope / current_price) * 100 if current_price > 0 else 0.0

def calc_sigma(prices, X, X_mean, X_var_sum):
    y_mean = np.mean(prices)
    slope = np.sum((X - X_mean) * (prices - y_mean)) / X_var_sum
    intercept = y_mean - slope * X_mean
    trend_line = slope * X + intercept
    std = np.std(prices - trend_line)
    return (prices[-1] - trend_line[-1]) / std if std > 0 else 0.0

def vectorized_reverse_price(hist_19_matrix, target_slopes):
    weights = np.arange(19) - 9.5
    K = np.sum(weights * hist_19_matrix, axis=1)
    denom = 6.65 * target_slopes - 9.5
    denom[np.abs(denom) < 0.01] = np.sign(denom[np.abs(denom) < 0.01]) * 0.01 + 1e-9
    raw_prices = K / denom
    last_prices = hist_19_matrix[:, -1]
    return np.clip(raw_prices, last_prices * 0.7, last_prices * 1.3)

def reverse_calculate_price(prev_19_prices, target_slope_pct):
    K = np.sum((np.arange(19) - 9.5) * prev_19_prices)
    denom = 6.65 * target_slope_pct - 9.5
    if abs(denom) < 0.01:
        denom = -0.01 if denom < 0 else 0.01
    raw_price = K / denom
    last_price = prev_19_prices[-1]
    return np.clip(raw_price, last_price * 0.7, last_price * 1.3)

# ---------------------------------------------------------
# âš™ï¸ 1. UI ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(page_title="Quantum Oracle V26.1", page_icon="ğŸ”®", layout="wide")

st.title("ğŸ”® The Quantum Oracle V26.1: ë°©í–¥ ì ì¤‘ë¥  & ì‹ ë¢° êµ¬ê°„")
st.markdown("""
ë‹¨ìˆœ ì˜¤ì°¨ í¬ê¸°ê°€ ì•„ë‹Œ, **"ì˜¤ëŠ˜ ì‚¬ì„œ Tì¼ ë’¤ì— íŒ”ì•˜ì„ ë•Œ ì˜¤ë¥´ê³  ë‚´ë¦¬ëŠ” 'ìˆ˜ìµ ë°©í–¥(Direction)'ì„ ì–¼ë§ˆë‚˜ ì˜ ë§ì·„ëŠ”ê°€(Hit Ratio %)"**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§„ì§œ 1ìœ„ Të¥¼ ì°¾ìŠµë‹ˆë‹¤.  
ë˜í•œ ë¯¸ë˜ ì£¼ê°€ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ì‹œê°í™”í•œ **80% ì‹ ë¢° êµ¬ê°„(Confidence Interval)** ë°´ë“œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
""")

with st.sidebar:
    st.header("âš™ï¸ ë”¥ìŠ¤ìº” ë¶„ì„ ì„¤ì •")
    target_ticker = st.text_input("ì¢…ëª© ì½”ë“œ (ìš°ëŸ‰ì£¼/ETF ê¶Œì¥)", value="069500.KS")
    run_btn = st.button("ğŸš€ ì „ì²´ ì—­ì‚¬ ë¶„ì„ ë° ì˜¤ëŠ˜ ì „ëµ ìƒì„±", type="primary")

# ---------------------------------------------------------
# âš™ï¸ 2. AI ë”¥ìŠ¤ìº” ë° ë©”íƒ€ ëª¨ë¸ ì—”ì§„
# ---------------------------------------------------------
@st.cache_data(show_spinner=False, ttl=3600)
def deep_scan_and_meta_predict(ticker):
    try:
        df_target = yf.download(ticker, start="2010-01-01", progress=False)
        df_vix = yf.download("^VIX", start="2010-01-01", progress=False)
        df_spx = yf.download("^GSPC", start="2010-01-01", progress=False)
        
        if df_target.empty: return None, "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨."
        
        for d in [df_target, df_vix, df_spx]:
            if isinstance(d.columns, pd.MultiIndex): d.columns = d.columns.get_level_values(0)

        df_target.index = df_target.index.tz_localize(None)
        df_vix.index = df_vix.index.tz_localize(None)
        df_spx.index = df_spx.index.tz_localize(None)

        df = pd.DataFrame(index=df_target.index)
        df['Close'] = df_target['Close']
        df['Volume'] = df_target['Volume']
        
        df = df.join(df_vix[['Close']].rename(columns={'Close': 'VIX'}), how='left')
        df = df.join(df_spx[['Close']].rename(columns={'Close': 'SPX'}), how='left')
        df.ffill(inplace=True)
        df.bfill(inplace=True)

        closes = df['Close'].values
        n_days = len(closes)
        if n_days < 500: return None, "ê³¼ê±° ë°ì´í„° ë¶€ì¡± (ìµœì†Œ 500ì¼ í•„ìš”)."

        X_20, X_m_20, X_v_20 = get_linear_params(20)
        X_60, X_m_60, X_v_60 = get_linear_params(60)
        
        df['Slope_20'] = np.nan
        df['Sigma_20'] = np.nan
        df['Slope_60'] = np.nan
        
        for i in range(60, n_days):
            p20 = closes[i-20+1 : i+1]
            p60 = closes[i-60+1 : i+1]
            df.loc[df.index[i], 'Slope_20'] = calc_fast_slope(p20, X_20, X_m_20, X_v_20)
            df.loc[df.index[i], 'Sigma_20'] = calc_sigma(p20, X_20, X_m_20, X_v_20)
            df.loc[df.index[i], 'Slope_60'] = calc_fast_slope(p60, X_60, X_m_60, X_v_60)

        df['Slope_Accel'] = df['Slope_20'] - df['Slope_20'].shift(1)
        df['Slope_Divergence'] = df['Slope_20'] - df['Slope_60']
        df['VIX_Change'] = df['VIX'].pct_change(5).fillna(0)
        
        df['Target_Slope_Next'] = df['Slope_20'].shift(-1)
        
        features = ['Sigma_20', 'Slope_20', 'Slope_60', 'Slope_Accel', 'Slope_Divergence', 'VIX_Change']
        
        today_row = df.iloc[-1]
        ml_df = df.dropna(subset=features + ['Target_Slope_Next']).copy()
        
        X_all = ml_df[features].values
        Y_slope = ml_df['Target_Slope_Next'].values
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_all)
        
        model_slope = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42, n_jobs=-1)
        model_slope.fit(X_scaled, Y_slope)

        residuals = Y_slope - model_slope.predict(X_scaled)
        res_std = np.std(residuals)

        # ---------------------------------------------------------
        # ğŸŒŸ ë°©í–¥ ì ì¤‘ë¥ (Hit Ratio) ê¸°ë°˜ ì´ˆê³ ì† ë²¡í„° ë°±í…ŒìŠ¤íŠ¸
        # ---------------------------------------------------------
        eval_df = ml_df.iloc[-420:-20].copy()
        N_eval = len(eval_df)
        
        hit_matrix = np.zeros((N_eval, 20)) 
        curr_state_matrix = eval_df[features].values 
        
        hist_idx = [np.where(df.index == d)[0][0] for d in eval_df.index]
        hist_prices_matrix = np.array([closes[idx-19 : idx+1] for idx in hist_idx])
        base_prices = hist_prices_matrix[:, -1] 
        
        for step in range(20):
            x_in_scaled = scaler.transform(curr_state_matrix)
            next_slopes = model_slope.predict(x_in_scaled)
            
            prev_19 = hist_prices_matrix[:, -19:]
            next_prices = vectorized_reverse_price(prev_19, next_slopes)
            
            hist_prices_matrix = np.hstack((hist_prices_matrix[:, 1:], next_prices.reshape(-1, 1)))
            
            actual_future_prices = np.array([closes[idx + step + 1] for idx in hist_idx])
            pred_direction = np.sign(next_prices - base_prices)
            actual_direction = np.sign(actual_future_prices - base_prices)
            
            hits = (pred_direction == actual_direction).astype(int)
            hit_matrix[:, step] = hits
            
            curr_state_matrix[:, features.index('Slope_Accel')] = next_slopes - curr_state_matrix[:, features.index('Slope_20')]
            curr_state_matrix[:, features.index('Slope_20')] = next_slopes
            curr_state_matrix[:, features.index('Sigma_20')] *= 0.9 

        # ---------------------------------------------------------
        # ğŸ§  ë©”íƒ€ ëª¨ë¸ í•™ìŠµ
        # ---------------------------------------------------------
        hit_rates_per_t = np.mean(hit_matrix, axis=0) * 100 
        passive_best_t = np.argmax(hit_rates_per_t) + 1 
        
        best_t_labels = []
        for i in range(N_eval):
            hits = hit_matrix[i]
            if np.sum(hits) == 0:
                best_t_labels.append(passive_best_t)
            else:
                valid_ts = np.where(hits == 1)[0]
                best_t_labels.append(valid_ts[-1] + 1)
        
        meta_features = eval_df[['Sigma_20', 'Slope_20']].values
        meta_clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
        meta_clf.fit(meta_features, best_t_labels)
        
        today_sigma = today_row['Sigma_20']
        today_slope = today_row['Slope_20']
        active_best_t = meta_clf.predict([[today_sigma, today_slope]])[0]
        meta_prob = np.max(meta_clf.predict_proba([[today_sigma, today_slope]])) * 100

        # ---------------------------------------------------------
        # ğŸ”® ì˜¤ëŠ˜ ê¸°ì¤€ ë¯¸ë˜ ì£¼ê°€ ì—­ì‚° & ì‹ ë¢° êµ¬ê°„ ìƒì„±
        # ---------------------------------------------------------
        today_state = {f: today_row[f] for f in features}
        today_hist = list(closes[-20:])
        
        sim_dates = []
        sim_prices_mean = []
        sim_prices_upper = [] 
        sim_prices_lower = [] 
        
        c_date = df.index[-1]
        cumulative_std = 0
        
        for step in range(20):
            x_in = scaler.transform([[today_state[f] for f in features]])
            base_slope = model_slope.predict(x_in)[0]
            
            cumulative_std += (res_std * np.sqrt(step + 1)) * 0.1 
            upper_slope = base_slope + (1.28 * cumulative_std)
            lower_slope = base_slope - (1.28 * cumulative_std)
            
            mean_price = reverse_calculate_price(np.array(today_hist[-19:]), base_slope)
            upper_price = reverse_calculate_price(np.array(today_hist[-19:]), upper_slope)
            lower_price = reverse_calculate_price(np.array(today_hist[-19:]), lower_slope)
            
            u_p, l_p = max(upper_price, lower_price), min(upper_price, lower_price)
            
            c_date += BDay(1)
            sim_dates.append(c_date)
            sim_prices_mean.append(mean_price)
            sim_prices_upper.append(u_p)
            sim_prices_lower.append(l_p)
            
            today_hist.append(mean_price)
            
            today_state['Slope_Accel'] = base_slope - today_state['Slope_20']
            today_state['Slope_20'] = base_slope
            today_state['Sigma_20'] *= 0.9

        past_dates = df.index[-20:].tolist()
        past_prices = closes[-20:].tolist()

        res = {
            'hit_rates': hit_rates_per_t,
            'passive_t': passive_best_t,
            'active_t': int(active_best_t),
            'meta_prob': meta_prob,
            'today_sigma': today_sigma,
            'today_slope': today_slope,
            'past_dates': past_dates,
            'past_prices': past_prices,
            'sim_dates': sim_dates,
            'sim_prices_mean': sim_prices_mean,
            'sim_prices_upper': sim_prices_upper,
            'sim_prices_lower': sim_prices_lower
        }
        return res, None

    except Exception as e:
        return None, f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ---------------------------------------------------------
# âš™ï¸ 3. í™”ë©´ ë Œë”ë§
# ---------------------------------------------------------
if run_btn:
    with st.spinner(f"ğŸ“¦ 400ì¼ì¹˜ ë°©í–¥ ì ì¤‘ë¥ (Hit Ratio) ë¶„ì„ ë° 80% ì‹ ë¢° êµ¬ê°„ì„ ì—°ì‚° ì¤‘ì…ë‹ˆë‹¤..."):
        res, err = deep_scan_and_meta_predict(target_ticker)
        
    if err:
        st.error(err)
    else:
        st.success(f"âœ… ë°©í–¥ ì ì¤‘ë¥  ìµœì í™” ë° ì‹ ë¢° ë°´ë“œ ìƒì„± ì™„ë£Œ!")
        
        c1, c2 = st.columns(2)
        
        with c1:
            st.markdown("#### ğŸŒ 1. íŒ¨ì‹œë¸Œ í†µê³„ (ìˆ˜ìµ ë°©í–¥ ì ì¤‘ë¥  ê¸°ì¤€)")
            st.info(f"ë‹¨ìˆœ ì˜¤ì°¨ê°€ ì•„ë‹Œ, ì§„ì… í›„ ì£¼ê°€ì˜ 'ìƒìŠ¹/í•˜ë½ ë°©í–¥'ì„ ê°€ì¥ ì˜ ë§ì¶˜ ê¸°ê°„ì…ë‹ˆë‹¤.\n\n"
                    f"ğŸ† **ì—­ì‚¬ì  ê³ ìœ  í˜¸í¡(ì „ì²´ 1ìœ„): T = {res['passive_t']}ì¼**\n\n"
                    f"(ì´ ì¢…ëª©ì€ ì§„ì… í›„ í‰ê· ì ìœ¼ë¡œ {res['passive_t']}ì¼ ì°¨ì— ê°€ì¥ ëšœë ·í•œ ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.)")
            
        with c2:
            st.markdown("#### ğŸ§  2. ë©”íƒ€ AI ì•¡í‹°ë¸Œ ì¶”ì²œ (ì˜¤ëŠ˜ ì¥ì„¸ ë§ì¶¤í˜•)")
            st.success(f"ì˜¤ëŠ˜ì˜ ìƒíƒœ (ì‹œê·¸ë§ˆ: {res['today_sigma']:.2f}, ê¸°ìš¸ê¸°: {res['today_slope']:.2f}%)\n\n"
                       f"ğŸ¯ **ì˜¤ëŠ˜ ì§„ì… ì‹œ ìµœì  ë§¤ë„ì¼: T = {res['active_t']}ì¼**\n\n"
                       f"*(AI íŒ¨í„´ í™•ì‹ ë„: {res['meta_prob']:.1f}% - ë¶ˆí™•ì‹¤í•œ ì¥ì„¸ë©´ íŒ¨ì‹œë¸Œ Të¥¼ ë”°ë¥´ì‹­ì‹œì˜¤)*")
        
        st.markdown("---")
        
        st.subheader("ğŸ“Š 3. ë³´ìœ ê¸°ê°„(T)ë³„ 'ìˆ˜ìµ ë°©í–¥ ì ì¤‘ë¥ ' ë­í‚¹ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
        rank_df = pd.DataFrame({
            'T (ë³´ìœ  ì¼ìˆ˜)': [f"{i+1}ì¼" for i in range(20)],
            'ì ì¤‘ë¥  (%)': res['hit_rates']
        })
        fig_bar = go.Figure(go.Bar(
            x=rank_df['T (ë³´ìœ  ì¼ìˆ˜)'], y=rank_df['ì ì¤‘ë¥  (%)'],
            marker=dict(color=['#27ae60' if i+1 == res['active_t'] else '#95a5a6' for i in range(20)])
        ))
        fig_bar.update_layout(height=300, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="ë°©í–¥ ì ì¤‘ë¥  (%)")
        st.plotly_chart(fig_bar, use_container_width=True)
        
        st.markdown("---")
        
        st.subheader(f"ğŸ“ˆ 4. í–¥í›„ 20ì¼ ì—­ì‚° ê¶¤ì  ë° 80% ì‹ ë¢° êµ¬ê°„ (Confidence Band)")
        st.markdown("> ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ AIì˜ ì˜ˆì¸¡ ì˜¤ì°¨ê°€ ëˆ„ì ë˜ëŠ” ê²ƒì„ ë°˜ì˜í•˜ì—¬, **ì£¼ê°€ê°€ í”ë“¤ë¦´ ìˆ˜ ìˆëŠ” ìƒí•˜ë‹¨ ë²”ìœ„(íšŒìƒ‰ ì˜ì—­)**ë¥¼ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
        
        fig_proj = go.Figure()
        
        conn_dates = [res['past_dates'][-1]] + res['sim_dates']
        conn_upper = [res['past_prices'][-1]] + res['sim_prices_upper']
        conn_lower = [res['past_prices'][-1]] + res['sim_prices_lower']
        
        fig_proj.add_trace(go.Scatter(
            x=conn_dates + conn_dates[::-1], 
            y=conn_upper + conn_lower[::-1],
            fill='toself',
            fillcolor='rgba(149, 165, 166, 0.2)',
            line=dict(color='rgba(255,255,255,0)'),
            hoverinfo="skip",
            showlegend=True,
            name='80% ì‹ ë¢° êµ¬ê°„'
        ))
        
        fig_proj.add_trace(go.Scatter(
            x=res['past_dates'], y=res['past_prices'], mode='lines+markers',
            line=dict(color='#2c3e50', width=4), name='ê³¼ê±° 20ì¼ ì‹¤ì œ ì£¼ê°€'
        ))
        
        conn_mean = [res['past_prices'][-1]] + res['sim_prices_mean']
        fig_proj.add_trace(go.Scatter(
            x=conn_dates, y=conn_mean, mode='lines+markers',
            line=dict(color='#e74c3c', width=3, dash='dot'), name='ì—­ì‚° ê¸°ë°˜ ë¯¸ë˜ ê¶¤ì  (í‰ê· )'
        ))
        
        # ğŸŒŸ ì¹˜ëª…ì ì¸ ë²„ê·¸ ìˆ˜ì •: Plotlyì˜ add_vline annotation_text ì—ëŸ¬ ì›ì²œ ì°¨ë‹¨
        rec_idx = res['active_t'] - 1
        rec_date = res['sim_dates'][rec_idx]
        
        # ì„  ê¸‹ê¸°
        fig_proj.add_vline(x=rec_date, line_dash="dash", line_color="green")
        
        # ê¸€ìëŠ” ì•ˆì „í•˜ê²Œ ë…ë¦½ì ì¸ add_annotationìœ¼ë¡œ ë¶„ë¦¬ ë°°ì¹˜
        fig_proj.add_annotation(
            x=rec_date, 
            y=1.05, # ê·¸ë˜í”„ ì‚´ì§ ìœ„ìª½ì— ìœ„ì¹˜
            yref="paper",
            text=f"ğŸ¯ AI ì•¡í‹°ë¸Œ íƒ€ê²Ÿ (T={res['active_t']})",
            showarrow=False,
            font=dict(color="green", size=13, weight="bold")
        )
        
        fig_proj.update_layout(hovermode="x unified", height=500, margin=dict(l=0, r=0, t=10, b=0), yaxis_title="ì£¼ê°€ (ì›)")
        st.plotly_chart(fig_proj, use_container_width=True)
